{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Splitting with Gini Index and Entropy\n",
    "- This will be repurposed from Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X,y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Equation 18.5 \n",
    "\n",
    "The goal of a Decision Tree is to find feature $j_i$ and threshold $t_i$ that minimizes the weighted sum of the cost of Left Subtree $c(D^L_i(j,t))$ and Right Subtree $c(D^R_i(j,t))$\n",
    "\n",
    "Or more precisely\n",
    "> $(j_i, t_i) = \\arg \\min_{j \\in \\{1,..,D\\}} \\min_{t \\in T_j} \\frac{|D^L_i (j,t)|}{|D_i|} c(D^L_i(j,t)) + \\frac{|D^R_i (j,t)|}{|D_i|} c(D^R_i(j,t))$\n",
    "\n",
    "We're implementing the equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index \n",
    "\n",
    "For classification, we first compute the empirical distribution over class labels for this node: \n",
    "\n",
    "> $\\hat{\\pi_{ic}} = \\frac{1}{ | D_i |} \\sum_{n \\in D_i}\\mathbb{ I(y_n = c) }$\n",
    "\n",
    "Given this, we can then compute the **Gini Index**\n",
    "\n",
    "> $G_i = \\sum_{c=1}^{C} \\hat{\\pi_{ic}} (1 - \\hat{\\pi_{ic}}) = \\sum_{c=1}^C \\hat{\\pi_{ic}} - \\sum_{c=1}^C \\hat{\\pi_{ic}}^2 = 1 - \\sum_{c=1} \\hat{\\pi_{ic}}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX.shape = \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my.shape = \u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print('X.shape = ', X.shape)\n",
    "print('y.shape = ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Investigate if the masking methods that was used on Decision Tree Regressor is also appropriate with Decision Tree Classifier.\n",
    "- Investigate if it makes more sense to One-Hot encode the classes or use Ordinal Methods instead. (Things are obvious based from the plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    num_cats = np.unique(y).shape[0]\n",
    "    return np.eye(num_cats)[y], num_cats\n",
    "\n",
    "y_one_hot, num_cats = one_hot_encode(y)\n",
    "feat_index = 0\n",
    "plt_figsize = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m feat_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39munique(X[:,feat_index])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m selected_feat \u001b[38;5;241m=\u001b[39m X[:,feat_index]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m is_left_sampler \u001b[38;5;241m=\u001b[39m (selected_feat \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m thresh)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "feat_index = 0\n",
    "\n",
    "thresh = np.unique(X[:,feat_index]).reshape(1,-1)\n",
    "selected_feat = X[:,feat_index].reshape(-1,1)\n",
    "is_left_sampler = (selected_feat <= thresh)\n",
    "is_right_sampler = ~is_left_sampler\n",
    "\n",
    "print('======================================')\n",
    "print('sample_size = ', X.shape[0])\n",
    "print('feat_size = ', X.shape[1])\n",
    "print('num_thresholds = ', thresh.shape[1])\n",
    "print('num_cats = ', num_cats)\n",
    "print('======================================')\n",
    "print('is_left_sampler.shape = ', is_left_sampler.shape)\n",
    "print('is_right_sampler.shape = ', is_right_sampler.shape)\n",
    "print('======================================')\n",
    "\n",
    "\n",
    "stacked_targets = np.hstack([y.reshape(-1,1)] * is_left_sampler.shape[1])\n",
    "left_sampled, right_sampled = is_left_sampler * stacked_targets, is_right_sampler * stacked_targets\n",
    "\n",
    "n_samples_left, n_samples_right = np.sum(is_left_sampler, axis=0), np.sum(is_right_sampler, axis=0)\n",
    "\n",
    "# Plot for left\n",
    "plt.figure(figsize=plt_figsize)\n",
    "plt.imshow(is_left_sampler.T)\n",
    "plt.title(f'is_left_sampler {is_left_sampler.shape}')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=plt_figsize)\n",
    "plt.imshow(left_sampled.T)\n",
    "plt.title(f'left_sampled {left_sampled.shape}')\n",
    "plt.show()\n",
    "\n",
    "# Plot for right\n",
    "plt.figure(figsize=plt_figsize)\n",
    "plt.imshow(is_right_sampler.T)\n",
    "plt.title(f'is_right_sampler {is_right_sampler.shape}')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=plt_figsize)\n",
    "plt.imshow(right_sampled.T)\n",
    "plt.title(f'right_sampled {right_sampled.shape}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
